---
phase: 05-observability-and-validation
plan: 02
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - tools/gsd-review-broker/tests/test_activity_feed.py
  - tools/gsd-review-broker/tests/test_stats.py
  - tools/gsd-review-broker/tests/test_e2e_workflow.py
autonomous: true

must_haves:
  truths:
    - "Activity feed correctly filters by status and category and includes message previews"
    - "Stats tool returns correct counts, rates, and timing even on empty databases"
    - "Full review lifecycle (create -> claim -> message -> verdict -> close) produces complete audit trail"
    - "Observability tools correctly surface data after each lifecycle step"
    - "E2E workflow with revision cycle (request_changes -> revise -> re-approve) is audited completely"
  artifacts:
    - path: "tools/gsd-review-broker/tests/test_activity_feed.py"
      provides: "Activity feed and audit log tool tests"
      min_lines: 80
    - path: "tools/gsd-review-broker/tests/test_stats.py"
      provides: "Stats and timeline tool tests"
      min_lines: 80
    - path: "tools/gsd-review-broker/tests/test_e2e_workflow.py"
      provides: "End-to-end workflow validation with observability verification"
      min_lines: 100
  key_links:
    - from: "test_activity_feed.py"
      to: "tools.get_activity_feed, tools.get_audit_log"
      via: "tool.fn() calls with MockContext"
      pattern: "get_activity_feed\\.fn\\("
    - from: "test_stats.py"
      to: "tools.get_review_stats, tools.get_review_timeline"
      via: "tool.fn() calls with MockContext"
      pattern: "get_review_stats\\.fn\\("
    - from: "test_e2e_workflow.py"
      to: "all tools (create, claim, message, verdict, close, feed, audit, stats, timeline)"
      via: "full lifecycle sequences with assertions at each step"
      pattern: "create_review\\.fn\\(.*claim_review\\.fn\\("
---

<objective>
Comprehensive test coverage for all four new observability tools and end-to-end workflow validation proving the complete GSD review lifecycle works with audit trail verification.

Purpose: Validate that the observability layer (Plan 01) works correctly across all scenarios -- filtering, edge cases, empty databases, full lifecycles, revision cycles, and counter-patches. These tests prove the Phase 5 success criteria are met.

Output: Three new test files covering activity feed, audit log, stats, timeline, and end-to-end workflow validation. Combined with Plan 01's audit tests, this brings total new test count to approximately 25-35 tests.
</objective>

<execution_context>
@C:\Users\Jacar\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Jacar\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-observability-and-validation/05-CONTEXT.md
@.planning/phases/05-observability-and-validation/05-RESEARCH.md
@.planning/phases/05-observability-and-validation/05-01-SUMMARY.md
@tools/gsd-review-broker/src/gsd_review_broker/tools.py
@tools/gsd-review-broker/src/gsd_review_broker/audit.py
@tools/gsd-review-broker/src/gsd_review_broker/models.py
@tools/gsd-review-broker/tests/conftest.py
@tools/gsd-review-broker/tests/test_proposals.py
@tools/gsd-review-broker/tests/test_messages.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Activity feed and audit log tool tests</name>
  <files>
    tools/gsd-review-broker/tests/test_activity_feed.py
  </files>
  <action>
    Create test_activity_feed.py with tests for get_activity_feed and get_audit_log tools. Use the existing conftest.py fixtures (ctx). Call tools via `.fn()` attribute (e.g., `get_activity_feed.fn(ctx=ctx)`). Import tools from `gsd_review_broker.tools`.

    **get_activity_feed tests:**

    1. **test_activity_feed_empty**: No reviews exist. Returns {"reviews": [], "count": 0}.

    2. **test_activity_feed_all_reviews**: Create 3 reviews (different statuses: one pending, one claimed, one approved). Call get_activity_feed with no filters. Verify all 3 returned, ordered by updated_at DESC. Verify each entry has: id, status, intent, agent_type, phase, priority, category, created_at, updated_at, message_count, last_message_at, last_message_preview.

    3. **test_activity_feed_filter_by_status**: Create 2 pending and 1 approved review. Filter by status="pending". Verify only 2 returned.

    4. **test_activity_feed_filter_by_category**: Create reviews with different categories. Filter by category="code_change". Verify only matching reviews returned.

    5. **test_activity_feed_filter_by_status_and_category**: Combine both filters. Verify AND logic.

    6. **test_activity_feed_message_preview**: Create a review, claim it, add a message with body longer than 120 chars. Call get_activity_feed. Verify last_message_preview is truncated to 120 chars, message_count is 1, last_message_at is not null.

    7. **test_activity_feed_iso8601_timestamps**: Create a review. Call get_activity_feed. Verify created_at and updated_at contain 'T' and end with 'Z' (ISO 8601 format).

    **get_audit_log tests:**

    8. **test_audit_log_empty**: No reviews/events. Returns {"events": [], "count": 0}.

    9. **test_audit_log_for_review**: Create a review (which records audit event via wiring). Call get_audit_log(review_id=...). Verify at least 1 event with event_type="review_created". Verify metadata is parsed as dict (not string).

    10. **test_audit_log_all_events**: Create 2 reviews. Call get_audit_log() with no review_id. Verify events from both reviews returned.

    11. **test_audit_log_nonexistent_review**: Call get_audit_log(review_id="nonexistent"). Returns error dict.

    12. **test_audit_log_event_ordering**: Create review, claim it, submit verdict. Call get_audit_log. Verify events are in chronological order (review_created before review_claimed before verdict_submitted).

    For claimed/approved reviews, use the full lifecycle: create_review -> claim_review -> submit_verdict. Mock validate_diff (from gsd_review_broker.diff_utils) to return (True, None) if any tests use diffs, or simply omit diffs for simplicity.
  </action>
  <verify>
    Run: `cd tools/gsd-review-broker && uv run pytest tests/test_activity_feed.py -v`
    All 12 tests pass.
  </verify>
  <done>
    Activity feed tests verify filtering (status, category, combined), message previews, ISO 8601 timestamps, and empty state. Audit log tests verify per-review and all-events retrieval, event ordering, metadata parsing, and error handling.
  </done>
</task>

<task type="auto">
  <name>Task 2: Stats, timeline, and end-to-end workflow validation tests</name>
  <files>
    tools/gsd-review-broker/tests/test_stats.py
    tools/gsd-review-broker/tests/test_e2e_workflow.py
  </files>
  <action>
    **test_stats.py**: Tests for get_review_stats and get_review_timeline tools.

    **get_review_stats tests:**

    1. **test_stats_empty_database**: No reviews. Returns total_reviews=0, all by_status counts 0, by_category empty, approval_rate_pct=None, avg_time_to_verdict_seconds=None, avg_review_duration_seconds=None.

    2. **test_stats_counts_by_status**: Create reviews in various statuses (pending, claimed, approved). Verify by_status counts match.

    3. **test_stats_counts_by_category**: Create reviews with different categories. Verify by_category dict has correct counts. Reviews with no category appear as "uncategorized".

    4. **test_stats_approval_rate**: Create 2 reviews. Approve one (create -> claim -> submit_verdict approved). Request changes on the other (create -> claim -> submit_verdict changes_requested). Verify approval_rate_pct is 50.0.

    5. **test_stats_timing_metrics**: Create a review, claim it, approve it, close it. Verify avg_time_to_verdict_seconds and avg_review_duration_seconds are both not None and are numeric (>= 0). Exact values depend on timing so just verify they exist and are reasonable.

    **get_review_timeline tests:**

    6. **test_timeline_nonexistent_review**: Call with nonexistent ID. Returns error dict.

    7. **test_timeline_single_event**: Create a review. Call get_review_timeline. Verify 1 event of type "review_created" with correct review_id, intent, current_status, category.

    8. **test_timeline_full_lifecycle**: Create -> claim -> approve -> close. Verify timeline has events in order: review_created, review_claimed, verdict_submitted, review_closed. Verify each event has ISO 8601 timestamp.

    9. **test_timeline_with_messages**: Create -> claim -> add_message -> add_message (alternate sender_role). Verify timeline includes message_sent events with metadata containing body_preview and round.

    10. **test_timeline_metadata_parsed**: Create a review (which stores metadata with intent and category). Verify the metadata field in the timeline event is a dict (not a JSON string).

    **test_e2e_workflow.py**: End-to-end validation proving the complete flow.

    **E2E tests:**

    11. **test_full_lifecycle_happy_path**: Complete happy path: create_review (code_change category) -> claim_review -> add_message (reviewer) -> add_message (proposer) -> submit_verdict (approved) -> close_review. After each step, verify:
        - Activity feed shows correct status
        - After close: timeline has all event types (review_created, review_claimed, message_sent x2, verdict_submitted, review_closed)
        - Stats show 1 total review, 1 closed, approval_rate_pct=100.0, timing metrics not null
        - Audit log has all events in order

    12. **test_revision_cycle**: Create -> claim -> request_changes -> revise (create_review with same review_id) -> claim again -> approve -> close. Verify:
        - Timeline shows: review_created, review_claimed, verdict_submitted (changes_requested), review_revised, review_claimed, verdict_submitted (approved), review_closed
        - Activity feed shows final status as closed
        - Stats reflect the single completed review

    13. **test_counter_patch_flow**: Create (with diff, mock validate_diff) -> claim -> submit_verdict with counter_patch (changes_requested) -> accept_counter_patch -> revise -> claim -> approve -> close. Verify timeline includes counter_patch_accepted event.

    14. **test_multiple_reviews_different_categories**: Create 3 reviews with different categories (plan_review, code_change, verification). Run each through different outcomes (approved, changes_requested, still pending). Verify:
        - Activity feed shows all 3
        - Stats by_category counts are correct
        - Filtering activity feed by category returns correct subsets

    15. **test_observability_tools_iso8601_consistency**: Create and process a review. Call all 4 observability tools. Verify every timestamp field in every response contains 'T' and ends with 'Z'.

    For any tests that use diffs, mock `gsd_review_broker.diff_utils.validate_diff` to return (True, None) and mock `gsd_review_broker.diff_utils.extract_affected_files` to return '["file.py"]'.
  </action>
  <verify>
    Run: `cd tools/gsd-review-broker && uv run pytest tests/test_stats.py tests/test_e2e_workflow.py -v`
    All tests pass. Then run full suite: `uv run pytest -v` -- all tests pass (existing + new).
  </verify>
  <done>
    Stats tests verify empty database handling, status/category counts, approval rates, and timing metrics. Timeline tests verify event ordering, metadata parsing, and ISO 8601 timestamps. E2E tests prove the complete lifecycle (happy path, revision cycle, counter-patch flow, multi-category) with observability verification at each step. Full test suite passes with zero regressions.
  </done>
</task>

</tasks>

<verification>
1. `cd tools/gsd-review-broker && uv run pytest -v` -- ALL tests pass (existing ~145 + Plan 01 audit tests + Plan 02 tests)
2. `uv run pytest tests/test_activity_feed.py tests/test_stats.py tests/test_e2e_workflow.py -v` -- all new tests pass
3. Total new tests from Phase 5: approximately 30+ across test_audit.py, test_activity_feed.py, test_stats.py, test_e2e_workflow.py
4. No test touches external services, subprocesses, or network -- all use MockContext with in-memory SQLite
</verification>

<success_criteria>
- Activity feed tool is tested for empty state, all reviews, each filter type, combined filters, message previews, ISO 8601 timestamps
- Audit log tool is tested for empty state, per-review retrieval, all-events retrieval, nonexistent review, event ordering
- Stats tool is tested for empty database edge case, status counts, category counts, approval rate, timing metrics
- Timeline tool is tested for nonexistent review, single event, full lifecycle, messages, metadata parsing
- E2E tests prove complete happy path, revision cycle, counter-patch flow, multi-category scenarios
- All timestamps in observability tool responses are ISO 8601 formatted
- Full test suite passes (existing + new) with zero regressions
</success_criteria>

<output>
After completion, create `.planning/phases/05-observability-and-validation/05-02-SUMMARY.md`
</output>
