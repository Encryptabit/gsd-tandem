---
phase: 05-observability-and-validation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tools/gsd-review-broker/src/gsd_review_broker/db.py
  - tools/gsd-review-broker/src/gsd_review_broker/models.py
  - tools/gsd-review-broker/src/gsd_review_broker/audit.py
  - tools/gsd-review-broker/src/gsd_review_broker/tools.py
  - tools/gsd-review-broker/tests/test_audit.py
autonomous: true

must_haves:
  truths:
    - "Audit events are recorded atomically with every state-changing operation"
    - "Activity feed shows all reviews with message previews, filterable by status and category"
    - "Stats tool returns total reviews, approval/rejection rates, reviews by category, average time-to-verdict, average review duration"
    - "Audit log returns append-only event history for a review or all reviews"
    - "Review timeline returns chronological event sequence for a single review"
    - "All new tool output uses ISO 8601 timestamps"
  artifacts:
    - path: "tools/gsd-review-broker/src/gsd_review_broker/audit.py"
      provides: "record_event helper for atomic audit insertion"
      exports: ["record_event"]
    - path: "tools/gsd-review-broker/src/gsd_review_broker/db.py"
      provides: "audit_events table schema migration"
      contains: "audit_events"
    - path: "tools/gsd-review-broker/src/gsd_review_broker/models.py"
      provides: "AuditEventType StrEnum"
      contains: "AuditEventType"
    - path: "tools/gsd-review-broker/src/gsd_review_broker/tools.py"
      provides: "4 new MCP tools + audit wiring in all existing handlers"
      exports: ["get_activity_feed", "get_audit_log", "get_review_stats", "get_review_timeline"]
    - path: "tools/gsd-review-broker/tests/test_audit.py"
      provides: "Tests for audit event recording helper"
      min_lines: 40
  key_links:
    - from: "tools.py (existing handlers)"
      to: "audit.py record_event"
      via: "import and call inside BEGIN IMMEDIATE...COMMIT blocks"
      pattern: "await record_event\\(app\\.db"
    - from: "tools.py (get_review_stats)"
      to: "audit_events table"
      via: "aggregate SQL queries on audit_events"
      pattern: "FROM audit_events"
    - from: "tools.py (get_review_timeline)"
      to: "audit_events table"
      via: "SELECT from audit_events WHERE review_id"
      pattern: "FROM audit_events.*WHERE review_id"
    - from: "tools.py (get_activity_feed)"
      to: "reviews + messages tables"
      via: "correlated subqueries for message preview"
      pattern: "FROM messages m WHERE m\\.review_id = r\\.id"
---

<objective>
Add audit event infrastructure, wire it into all existing tool handlers, and implement four new observability MCP tools (activity feed, audit log, stats, review timeline).

Purpose: Enable real-time visibility into broker activity and complete review history with audit trail. This is the production code for Phase 5 -- all schema changes, the audit helper module, audit wiring into existing handlers, and new observability tools.

Output: audit.py module, schema migration for audit_events table, AuditEventType enum, 4 new MCP tools registered on the FastMCP server, audit event recording in all 11 state-changing operations, and unit tests for the audit helper.
</objective>

<execution_context>
@C:\Users\Jacar\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Jacar\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-observability-and-validation/05-CONTEXT.md
@.planning/phases/05-observability-and-validation/05-RESEARCH.md
@tools/gsd-review-broker/src/gsd_review_broker/db.py
@tools/gsd-review-broker/src/gsd_review_broker/models.py
@tools/gsd-review-broker/src/gsd_review_broker/tools.py
@tools/gsd-review-broker/src/gsd_review_broker/server.py
@tools/gsd-review-broker/tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Audit infrastructure -- schema migration, AuditEventType enum, record_event helper</name>
  <files>
    tools/gsd-review-broker/src/gsd_review_broker/db.py
    tools/gsd-review-broker/src/gsd_review_broker/models.py
    tools/gsd-review-broker/src/gsd_review_broker/audit.py
    tools/gsd-review-broker/tests/test_audit.py
  </files>
  <action>
    **db.py**: Add Phase 5 schema migration entries to SCHEMA_MIGRATIONS list. Use CREATE TABLE IF NOT EXISTS (not ALTER TABLE) since this is a new table. Add 3 entries:
    1. CREATE TABLE IF NOT EXISTS audit_events with columns: id (INTEGER PRIMARY KEY AUTOINCREMENT), review_id (TEXT NOT NULL REFERENCES reviews(id)), event_type (TEXT NOT NULL), actor (TEXT), old_status (TEXT), new_status (TEXT), metadata (TEXT), created_at (TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')))
    2. CREATE INDEX IF NOT EXISTS idx_audit_review ON audit_events(review_id)
    3. CREATE INDEX IF NOT EXISTS idx_audit_type ON audit_events(event_type)

    Note: CREATE TABLE IF NOT EXISTS is naturally idempotent, so the existing migration error handling (catches duplicate-column errors) will simply pass through without issue. CREATE INDEX IF NOT EXISTS is also idempotent.

    **models.py**: Add AuditEventType StrEnum class with these members: REVIEW_CREATED = "review_created", REVIEW_REVISED = "review_revised", REVIEW_CLAIMED = "review_claimed", REVIEW_AUTO_REJECTED = "review_auto_rejected", VERDICT_SUBMITTED = "verdict_submitted", VERDICT_COMMENT = "verdict_comment", REVIEW_CLOSED = "review_closed", COUNTER_PATCH_ACCEPTED = "counter_patch_accepted", COUNTER_PATCH_REJECTED = "counter_patch_rejected", MESSAGE_SENT = "message_sent". Place it after the existing Category class.

    **audit.py** (NEW): Create a new module with a single async function:
    ```python
    async def record_event(
        db: aiosqlite.Connection,
        review_id: str,
        event_type: str,
        actor: str | None = None,
        old_status: str | None = None,
        new_status: str | None = None,
        metadata: dict | None = None,
    ) -> None:
    ```
    This function inserts into audit_events. It must be called INSIDE an existing BEGIN IMMEDIATE...COMMIT transaction. Use `json.dumps(metadata) if metadata else None` for the metadata column. Use `strftime('%Y-%m-%dT%H:%M:%fZ', 'now')` for created_at in the INSERT (matching the DEFAULT, but explicit for clarity). Import json and aiosqlite at module level.

    **test_audit.py** (NEW): Test the record_event helper:
    1. test_record_event_basic: Create a review, begin transaction, call record_event with all fields populated, commit, verify row exists in audit_events with correct values. Parse metadata JSON to confirm dict roundtrip.
    2. test_record_event_minimal: Call with only review_id and event_type (all optional fields None). Verify row exists with NULL for actor, old_status, new_status, metadata.
    3. test_record_event_timestamps_iso8601: Verify the created_at column value matches ISO 8601 pattern (contains 'T' and ends with 'Z').
    4. test_record_event_multiple_events_same_review: Insert 3 events for the same review_id, verify all 3 exist and autoincrement IDs are sequential.

    Use the existing conftest.py fixtures (db, ctx). For test_audit.py, you only need the db fixture since record_event takes a raw db connection. Create a helper review insert at the start of each test to satisfy the foreign key constraint.
  </action>
  <verify>
    Run: `cd tools/gsd-review-broker && uv run pytest tests/test_audit.py -v`
    All 4 tests pass. Also run `uv run pytest tests/test_db_schema.py -v` to confirm schema migration works.
  </verify>
  <done>
    audit_events table created via schema migration. AuditEventType StrEnum defined. record_event helper function works correctly with atomic transaction insertion. All 4 audit tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire audit events into all existing handlers + add 4 observability tools</name>
  <files>
    tools/gsd-review-broker/src/gsd_review_broker/tools.py
  </files>
  <action>
    This task modifies tools.py extensively. Read the full file first.

    **Part A: Add audit wiring to ALL existing state-changing handlers.**

    Add `from gsd_review_broker.audit import record_event` at the top of tools.py.

    Wire record_event calls INSIDE the BEGIN IMMEDIATE...COMMIT blocks (before COMMIT) in each handler. Use the AuditEventType string values directly (not the enum -- keep it simple since the field is TEXT). Here is the complete wiring checklist:

    1. **create_review (NEW review path)**: Before the COMMIT in the new review flow, add:
       `await record_event(app.db, new_review_id, "review_created", actor=agent_type, new_status="pending", metadata={"intent": intent, "category": category})`

    2. **create_review (REVISION path)**: Before the COMMIT in the revision flow, add:
       `await record_event(app.db, review_id, "review_revised", actor=agent_type, old_status="changes_requested", new_status="pending", metadata={"round": ...})`
       For the round metadata, you need to query current_round before the UPDATE (or use current_round+1 from the UPDATE). Simplest: just note it was revised. Use metadata={"revised": True}.

    3. **claim_review (successful claim)**: Before the COMMIT on the successful claim path (when auto_rejected_result is None), add:
       `await record_event(app.db, review_id, "review_claimed", actor=reviewer_id, old_status="pending", new_status="claimed")`

    4. **claim_review (auto-reject)**: Before the COMMIT on the auto-reject path, add:
       `await record_event(app.db, review_id, "review_auto_rejected", actor="broker-validator", old_status="pending", new_status="changes_requested", metadata={"reason": error_detail})`

    5. **submit_verdict (comment path)**: Before the COMMIT in the comment branch, add:
       `await record_event(app.db, review_id, "verdict_comment", actor="reviewer", old_status=str(current_status), new_status=str(current_status), metadata={"reason": normalized_reason, "has_counter_patch": counter_patch is not None})`

    6. **submit_verdict (approved/changes_requested)**: Before the COMMIT in the standard verdict branch, add:
       `await record_event(app.db, review_id, "verdict_submitted", actor="reviewer", old_status=str(current_status), new_status=str(target_status), metadata={"verdict": verdict, "has_counter_patch": counter_patch is not None})`

    7. **close_review**: Before the COMMIT, add:
       `await record_event(app.db, review_id, "review_closed", actor="system", old_status=str(current_status), new_status="closed")`

    8. **accept_counter_patch**: Before the COMMIT, add:
       `await record_event(app.db, review_id, "counter_patch_accepted", actor="proposer")`

    9. **reject_counter_patch**: Before the COMMIT, add:
       `await record_event(app.db, review_id, "counter_patch_rejected", actor="proposer")`

    10. **add_message**: Before the COMMIT, add:
        `await record_event(app.db, review_id, "message_sent", actor=sender_role, metadata={"round": current_round, "body_preview": body[:100]})`

    IMPORTANT: Do NOT log audit events for diff validation results or notification events (per user decision). Only lifecycle transitions and message exchanges.

    **Part B: Add 4 new MCP tools at the bottom of tools.py.**

    All new tools use `@mcp.tool` decorator, take `ctx: Context = None`, and return `dict`.

    **Tool 1: get_activity_feed(status: str | None = None, category: str | None = None, ctx: Context = None) -> dict**
    - Full activity feed showing all reviews with message previews
    - Use a single SQL query with correlated subqueries for message_count, last_message_at, last_message_preview (SUBSTR body to 120 chars)
    - Format all timestamps with strftime('%Y-%m-%dT%H:%M:%fZ', column) for ISO 8601
    - Build WHERE clause dynamically from optional status and category params
    - ORDER BY r.updated_at DESC
    - Return {"reviews": [...], "count": N}
    - Each review dict includes: id, status, intent, agent_type, phase, plan, task, priority, category, claimed_by, verdict_reason, created_at, updated_at, message_count, last_message_at, last_message_preview
    - See RESEARCH.md Pattern 3 for the exact SQL query

    **Tool 2: get_audit_log(review_id: str | None = None, ctx: Context = None) -> dict**
    - Returns audit events from the append-only audit_events table
    - If review_id provided: events for that review only (verify review exists first, return error if not)
    - If review_id omitted: ALL events across all reviews (per "history returns everything" decision)
    - ORDER BY id ASC (autoincrement guarantees insertion order)
    - Format created_at as ISO 8601 using strftime
    - Parse metadata JSON back into dict for each event
    - Return {"events": [...], "count": N} (and "review_id" if filtered)

    **Tool 3: get_review_stats(ctx: Context = None) -> dict**
    - Workflow health statistics. No parameters.
    - Query 1: Status counts from reviews table (total, pending, claimed, approved, changes_requested, closed). Use SUM(CASE WHEN ...) pattern.
    - Query 2: Category breakdown. SELECT COALESCE(category, 'uncategorized'), COUNT(*) GROUP BY category.
    - Query 3: Approval rate. Count distinct review_ids with verdict_submitted events where metadata contains verdict=approved, divided by total distinct review_ids with any verdict_submitted event. Use NULLIF guard. Return null if no verdicts.
    - Query 4: Average time-to-verdict in seconds. JOIN reviews with first verdict_submitted audit_event per review. Use (julianday(ae.created_at) - julianday(r.created_at)) * 86400. Return null if no verdicts.
    - Query 5: Average review duration in seconds (created to closed). JOIN reviews with review_closed audit_event. Use same julianday pattern. Return null if no closed reviews.
    - Round numeric values to 1 decimal place where not null.
    - Return {"total_reviews": N, "by_status": {...}, "by_category": {...}, "approval_rate_pct": N|null, "avg_time_to_verdict_seconds": N|null, "avg_review_duration_seconds": N|null}

    **Tool 4: get_review_timeline(review_id: str, ctx: Context = None) -> dict**
    - Chronological event timeline for a single review
    - Verify review exists, return error dict if not
    - Query audit_events WHERE review_id = ? ORDER BY id ASC
    - Format timestamps as ISO 8601
    - Parse metadata JSON
    - Only include old_status and new_status in event dict if non-null
    - Only include metadata in event dict if non-null
    - Return {"review_id": ..., "intent": ..., "current_status": ..., "category": ..., "events": [...], "event_count": N}
  </action>
  <verify>
    Run: `cd tools/gsd-review-broker && uv run pytest -v`
    ALL existing 145 tests still pass (no regressions from audit wiring). The audit wiring calls are inside existing transactions, so they should not affect existing test behavior beyond adding rows to audit_events (which existing tests don't query).
  </verify>
  <done>
    tools.py has audit event recording wired into all 11 state-changing operations (10 listed above, covering create_review new + revision paths). Four new MCP tools (get_activity_feed, get_audit_log, get_review_stats, get_review_timeline) are registered and return structured dict responses with ISO 8601 timestamps. All existing 145 tests pass without regression.
  </done>
</task>

</tasks>

<verification>
1. `cd tools/gsd-review-broker && uv run pytest -v` -- all tests pass (existing 145 + new audit tests)
2. `uv run pytest tests/test_audit.py -v` -- audit helper tests pass
3. Grep for record_event calls in tools.py -- should find 11 occurrences (one per state-changing operation)
4. Grep for `@mcp.tool` in tools.py -- should find 14 total (10 existing + 4 new)
5. Verify no import errors: `uv run python -c "from gsd_review_broker.audit import record_event; print('OK')"`
</verification>

<success_criteria>
- audit_events table exists via schema migration and persists through ensure_schema
- record_event helper inserts events atomically within transactions
- All 11 state-changing operations in tools.py record audit events
- get_activity_feed returns reviews with message previews, filtered by status/category, ISO 8601 timestamps
- get_audit_log returns append-only event history for one review or all reviews
- get_review_stats returns counts, rates, timing metrics (null-safe for empty databases)
- get_review_timeline returns chronological event sequence for a single review
- All existing 145 tests pass without regression
- New audit tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/05-observability-and-validation/05-01-SUMMARY.md`
</output>
