---
phase: 07-add-reviewer-lifecycle-management-to-broker
plan: 04
type: execute
wave: 3
depends_on: ["07-02", "07-03"]
files_modified:
  - tools/gsd-review-broker/src/gsd_review_broker/db.py
  - tools/gsd-review-broker/src/gsd_review_broker/server.py
  - tools/gsd-review-broker/src/gsd_review_broker/tools.py
  - tools/gsd-review-broker/tests/test_scaling.py
  - tools/gsd-review-broker/tests/conftest.py
autonomous: true
requirements:
  - RLMC-02
  - RLMC-05
  - RLMC-08

must_haves:
  truths:
    - "Background scaling task runs periodically and checks idle/TTL/claim timeouts"
    - "Ratio-based scaling spawns a reviewer when pending > scaling_ratio * active_reviewers"
    - "create_review triggers reactive scaling check"
    - "Idle timeout terminates reviewers with no activity beyond configured duration"
    - "TTL expiry triggers graceful drain (finish current review, then terminate)"
    - "Claim timeout reclaims reviews stuck in claimed state beyond 20 minutes"
    - "Claim timeout uses COALESCE(claimed_at, updated_at, created_at) so NULL claimed_at rows are reclaimable"
    - "spawn_reviewer MCP tool exposes manual spawn with pool cap enforcement"
    - "kill_reviewer MCP tool terminates only broker-managed reviewer IDs"
    - "Stale session reviewers are terminated on broker startup"
    - "Startup ownership sweep reclaims ALL claimed reviews not owned by a live current-session reviewer"
    - "Startup preserves claims owned by live current-session reviewers (active/draining)"
    - "Startup reclaims claims with NULL claimed_by or claimed_by referencing a foreign/missing reviewer"
    - "Pool integrates with broker lifespan (start background tasks, shutdown on exit)"
  artifacts:
    - path: "tools/gsd-review-broker/src/gsd_review_broker/db.py"
      provides: "AppContext with pool field, lifespan with background tasks, broadened stale session recovery with ownership sweep"
      contains: "pool: ReviewerPool"
    - path: "tools/gsd-review-broker/src/gsd_review_broker/tools.py"
      provides: "spawn_reviewer and kill_reviewer MCP tools, reactive scaling in create_review"
      exports: ["spawn_reviewer", "kill_reviewer"]
    - path: "tools/gsd-review-broker/tests/test_scaling.py"
      provides: "Tests for auto-scaling, idle timeout, TTL, claim timeout, stale session recovery, ownership sweep, NULL claimed_at fallback, drain lifecycle completion"
      min_lines: 150
  key_links:
    - from: "tools/gsd-review-broker/src/gsd_review_broker/db.py"
      to: "tools/gsd-review-broker/src/gsd_review_broker/pool.py"
      via: "ReviewerPool created in lifespan"
      pattern: "ReviewerPool.*session_token"
    - from: "tools/gsd-review-broker/src/gsd_review_broker/tools.py"
      to: "tools/gsd-review-broker/src/gsd_review_broker/pool.py"
      via: "pool.spawn_reviewer and pool.drain_reviewer calls"
      pattern: "app\\.pool\\.spawn_reviewer|app\\.pool\\.drain_reviewer"
    - from: "tools/gsd-review-broker/src/gsd_review_broker/db.py"
      to: "background tasks"
      via: "asyncio.create_task for periodic checks"
      pattern: "asyncio\\.create_task.*periodic"
    - from: "tools/gsd-review-broker/src/gsd_review_broker/db.py"
      to: "ownership sweep SQL"
      via: "NOT IN subquery for live current-session reviewers"
      pattern: "NOT IN.*SELECT.*FROM reviewers.*WHERE.*session_token.*status"
---

<objective>
Auto-scaling, background tasks, MCP tools, lifespan integration, broadened stale session recovery with ownership sweep, and NULL claimed_at handling.

Purpose: Wire the ReviewerPool (plan 02) and fenced reclaim (plan 03) into the broker's runtime: background tasks for periodic scaling/reclaim checks, reactive scaling on create_review, manual spawn/kill MCP tools, and comprehensive stale session recovery on startup. The startup recovery includes both terminating stale reviewers AND a broadened ownership sweep that reclaims ALL claimed reviews not owned by a live current-session reviewer (catching orphaned claims from crashes, foreign sessions, or NULL claimed_by). This completes the reviewer lifecycle management system.
Output: Fully integrated pool with auto-scaling, background tasks, manual override tools, broadened startup recovery, and comprehensive tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-add-reviewer-lifecycle-management-to-broker/07-RESEARCH.md
@.planning/phases/07-add-reviewer-lifecycle-management-to-broker/07-01-SUMMARY.md
@.planning/phases/07-add-reviewer-lifecycle-management-to-broker/07-02-SUMMARY.md
@.planning/phases/07-add-reviewer-lifecycle-management-to-broker/07-03-SUMMARY.md
@tools/gsd-review-broker/src/gsd_review_broker/db.py
@tools/gsd-review-broker/src/gsd_review_broker/pool.py
@tools/gsd-review-broker/src/gsd_review_broker/tools.py
@tools/gsd-review-broker/src/gsd_review_broker/config_schema.py
@tools/gsd-review-broker/tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Lifespan integration, background tasks, broadened stale session recovery, and NULL claimed_at handling</name>
  <files>
    tools/gsd-review-broker/src/gsd_review_broker/db.py
    tools/gsd-review-broker/tests/conftest.py
  </files>
  <action>
  **db.py -- AppContext update:**
  Add `pool: ReviewerPool | None = None` field to AppContext dataclass. Import ReviewerPool from pool module.

  **db.py -- broker_lifespan update:**
  After `ensure_schema(db)` and before `yield`:

  1. Load spawn config: Try to load via `load_spawn_config(config_path)` from config_schema module, passing the path to `.planning/config.json`. Handle the three cases:
     - `FileNotFoundError`: config file doesn't exist -- set pool to None, log "No config file, pool disabled".
     - Return value is `None`: config exists but no `reviewer_pool` key -- set pool to None, log "No reviewer_pool config, pool disabled". This is the canonical behavior established in plan 01: missing key = pool disabled.
     - Return value is a `SpawnConfig`: pool is enabled -- proceed with pool creation.

  2. If config loaded successfully (SpawnConfig returned), create `ReviewerPool(session_token=secrets.token_hex(4), config=spawn_config)`.

  3. **Stale session recovery (step 1 -- terminate stale reviewers):** Query `SELECT id, session_token, status FROM reviewers WHERE status IN ('active', 'draining')`. For each reviewer with a session_token different from the current pool's session_token, UPDATE status to 'terminated', set terminated_at. Log how many stale reviewers were terminated.

  4. **Stale session recovery (step 2 -- broadened ownership sweep over ALL claimed reviews):** After terminating stale reviewers, perform a FALLBACK SWEEP over ALL claimed reviews to reclaim any that are not owned by a live current-session reviewer:

     ```sql
     SELECT id, claimed_by FROM reviews WHERE status = 'claimed'
       AND (
         claimed_by IS NULL
         OR claimed_by NOT IN (
           SELECT id FROM reviewers
           WHERE session_token = ? AND status IN ('active', 'draining')
         )
       )
     ```

     Pass the current pool's session_token as the parameter. For each matched review, call `reclaim_review(review_id, app, reason="stale_session")`.

     This catches:
     - Reviews with NULL claimed_by (orphaned from crashes)
     - Reviews claimed by reviewers from a foreign/previous session
     - Reviews claimed by reviewers that no longer exist in the reviewers table
     - Reviews claimed by terminated reviewers from the current session

     Claims owned by live current-session reviewers (active or draining with matching session_token) are left untouched.

     Log how many reviews were reclaimed in the ownership sweep.

  5. Start background tasks:
     ```python
     scaling_task = asyncio.create_task(_periodic_check(ctx, "scaling"))
     ```
     Create a single `_periodic_check` async function (defined at module level or as a standalone function in db.py) that runs in a `while True` loop:
     - `await asyncio.sleep(config.background_check_interval_seconds)`
     - Call `await _check_idle_timeouts(ctx)` -- query reviewers with last_active_at older than idle_timeout, drain them.
     - Call `await _check_ttl_expiry(ctx)` -- query reviewers with spawned_at older than max_ttl, drain them.
     - Call `await _check_claim_timeouts(ctx)` -- query reviews WHERE status='claimed' AND claim is timed out, reclaim them.
     - Call `await _check_dead_processes(ctx)` -- iterate pool._processes, check proc.returncode is not None (process exited), clean up.
     - Wrap each check in try/except (log errors, don't crash the background task).
     - Handle `asyncio.CancelledError` by re-raising for clean shutdown.

  6. Set `ctx.pool = pool` before yield.

  7. In the `finally` block (before db close):
     - Cancel background task(s).
     - Await cancelled tasks with `suppress(CancelledError)`.
     - If pool exists, call `await pool.shutdown_all(db, write_lock)`.

  **conftest.py update:**
  Update the `ctx` fixture to include `pool=None` in AppContext construction so existing tests keep working. Pool-enabled tests will set it explicitly.

  **Helper functions** (defined in db.py or in a new module, at your discretion):

  `_check_idle_timeouts(ctx)`: Query reviewers WHERE status='active' AND last_active_at < datetime('now', '-{idle_timeout} seconds'). For each, call `pool.drain_reviewer(id, db, write_lock, reason="idle")`.

  `_check_ttl_expiry(ctx)`: Query reviewers WHERE status='active' AND spawned_at < datetime('now', '-{max_ttl} seconds'). For each, call `pool.drain_reviewer(id, db, write_lock, reason="ttl")`.

  `_check_claim_timeouts(ctx)`: Query reviews WHERE status='claimed' AND the claim has exceeded the timeout. **CRITICAL: Use `COALESCE(claimed_at, updated_at, created_at)` as the timestamp** so that legacy rows with NULL `claimed_at` cannot become permanently unreclaimable. The query should be:
  ```sql
  SELECT id FROM reviews WHERE status = 'claimed'
    AND COALESCE(claimed_at, updated_at, created_at) < datetime('now', '-{claim_timeout} seconds')
  ```
  For each matched review, call `reclaim_review(review_id, app, reason="claim_timeout")`. Import reclaim_review from tools module.

  Note: The startup ownership sweep (step 4) ignores `claimed_at` entirely -- it is purely ownership-based (does the claimed_by reference a live reviewer?). The periodic `_check_claim_timeouts` is the only place that uses time-based reclaim, and it uses COALESCE for NULL safety.

  `_check_dead_processes(ctx)`: Iterate pool._processes items. If proc.returncode is not None, the process exited unexpectedly. Record reviewer_terminated audit event, update DB, remove from _processes.
  </action>
  <verify>
  Run `cd C:/Projects/gsd-tandem/tools/gsd-review-broker && uv run pytest tests/ -v` -- ALL existing tests still pass (pool=None means no pool features activate). Verify broker_lifespan creates and cleans up background tasks. Verify load_spawn_config returning None results in pool=None (not a crash). Verify the ownership sweep SQL uses the NOT IN subquery pattern. Verify _check_claim_timeouts uses COALESCE(claimed_at, updated_at, created_at).
  </verify>
  <done>
  AppContext has pool field. broker_lifespan creates ReviewerPool if config exists AND has reviewer_pool key, starts background tasks, recovers stale sessions with broadened ownership sweep on startup, shuts down cleanly. Startup ownership sweep reclaims ALL claimed reviews not owned by live current-session reviewers (handles NULL claimed_by, foreign sessions, missing reviewer rows). Periodic claim timeout uses COALESCE for NULL claimed_at safety. When load_spawn_config returns None (no reviewer_pool key), pool is disabled gracefully. Existing tests unaffected (pool=None by default).
  </done>
</task>

<task type="auto">
  <name>Task 2: MCP tools (spawn/kill), reactive scaling, and comprehensive tests including drain lifecycle and ownership sweep</name>
  <files>
    tools/gsd-review-broker/src/gsd_review_broker/tools.py
    tools/gsd-review-broker/tests/test_scaling.py
  </files>
  <action>
  **tools.py -- Add spawn_reviewer MCP tool:**
  ```python
  @mcp.tool
  async def spawn_reviewer(ctx: Context = None) -> dict:
  ```
  - Get app context. If app.pool is None, return error: "Reviewer pool not configured. Add reviewer_pool section to config."
  - Acquire pool._spawn_lock to serialize scaling decisions.
  - Call `app.pool.spawn_reviewer(app.db, app.write_lock)`.
  - Return result (success or error from pool).
  - Log spawn result.

  **tools.py -- Add kill_reviewer MCP tool:**
  ```python
  @mcp.tool
  async def kill_reviewer(reviewer_id: str, ctx: Context = None) -> dict:
  ```
  - Get app context. If app.pool is None, return error.
  - Validate reviewer_id exists in pool._processes (cannot kill arbitrary processes per user decision).
  - Call `app.pool.drain_reviewer(reviewer_id, app.db, app.write_lock, reason="manual")`.
  - Return result.
  - Log kill result.

  **tools.py -- Add reactive scaling to create_review:**
  At the END of the `create_review` function (after the notification calls, before the final return), add:
  ```python
  # Reactive scaling check
  if app.pool is not None:
      asyncio.create_task(_reactive_scale_check(app))
  ```

  Create `_reactive_scale_check(app)` as an async function:
  - Count pending reviews: SELECT COUNT(*) FROM reviews WHERE status='pending'.
  - Count active reviewers: app.pool.active_count.
  - If active_count == 0 and pending > 0: spawn (cold start).
  - Elif pending > app.pool.config.scaling_ratio * active_count: spawn.
  - Else: do nothing.
  - Wrap in try/except to prevent create_review from failing due to scaling errors.
  - Use pool._spawn_lock to prevent concurrent scaling decisions.

  **tools.py -- Add list_reviewers MCP tool:**
  ```python
  @mcp.tool
  async def list_reviewers(ctx: Context = None) -> dict:
  ```
  - If app.pool is None, return error.
  - Query reviewers table: SELECT id, display_name, status, pid, spawned_at, last_active_at, reviews_completed, total_review_seconds, approvals, rejections FROM reviewers WHERE session_token = pool.session_token ORDER BY spawned_at ASC.
  - Return list of reviewer dicts.
  - Include pool_size (active count) and session_token in response for debugging.

  **test_scaling.py -- Comprehensive tests** (mock subprocess throughout):

  1. **test_spawn_reviewer_tool**: Call spawn_reviewer via tool .fn, verify success response with reviewer_id.
  2. **test_spawn_reviewer_pool_not_configured**: Set app.pool = None, call spawn_reviewer, verify error.
  3. **test_kill_reviewer_tool**: Spawn a reviewer, then kill it, verify drain initiated.
  4. **test_kill_reviewer_unknown_id**: Call kill_reviewer with unknown ID, verify error.
  5. **test_kill_reviewer_pool_not_configured**: Set app.pool = None, verify error.
  6. **test_reactive_scaling_cold_start**: Create a review with pool active (0 reviewers, 1 pending), verify spawn triggered.
  7. **test_reactive_scaling_ratio**: Set scaling_ratio=3, have 1 active reviewer and 4 pending reviews, verify spawn triggered.
  8. **test_reactive_scaling_sufficient_reviewers**: 1 active reviewer, 2 pending reviews (ratio 3:1 not exceeded), verify no spawn.
  9. **test_idle_timeout_triggers_drain**: Create reviewer, set last_active_at to old timestamp, run _check_idle_timeouts, verify drain called.
  10. **test_ttl_expiry_triggers_drain**: Create reviewer, set spawned_at to old timestamp, run _check_ttl_expiry, verify drain called.
  11. **test_claim_timeout_triggers_reclaim**: Create and claim a review, set claimed_at to old timestamp, run _check_claim_timeouts, verify reclaim called and review back to pending.
  12. **test_stale_session_recovery_on_startup**: Insert reviewer rows with different session_token, insert claimed reviews referencing those reviewers, simulate startup recovery logic, verify reviewers marked terminated and reviews reclaimed.
  13. **test_list_reviewers_tool**: Spawn reviewer, call list_reviewers, verify response contains the reviewer.
  14. **test_dead_process_cleanup**: Mock a process with returncode != None, run _check_dead_processes, verify reviewer terminated and cleaned up.

  **Additional drain lifecycle tests (from reviewer feedback Issue 1):**

  15. **test_reject_claim_for_draining_reviewer**: Insert a reviewer row with status='draining' into the reviewers table. Create a pending review. Call claim_review with that reviewer_id. Verify error response indicating the reviewer cannot claim because it is draining. (Note: This overlaps with test_reclaim.py test 18 but validates the integration in the scaling test context.)

  16. **test_reject_claim_for_terminated_reviewer**: Insert a reviewer row with status='terminated'. Create a pending review. Call claim_review with that reviewer_id. Verify error response.

  17. **test_terminate_draining_reviewer_after_terminal_verdict**: Set up a reviewer as 'draining' with exactly one claimed review. Submit a terminal verdict (approved) on that review. Verify the reviewer's status transitions to 'terminated' with terminated_at set and a reviewer_terminated audit event recorded.

  18. **test_terminate_draining_reviewer_after_reclaim**: Set up a reviewer as 'draining' with exactly one claimed review. Reclaim that review. Verify the reviewer's status transitions to 'terminated' with terminated_at set and a reviewer_terminated audit event recorded.

  19. **test_no_termination_when_other_claims_remain**: Set up a reviewer as 'draining' with TWO claimed reviews. Submit a terminal verdict on ONE. Verify the reviewer is still 'draining' (not terminated) because one claimed review remains.

  **Additional startup ownership sweep tests (from reviewer feedback Issue 2):**

  20. **test_startup_reclaims_claimed_review_with_missing_reviewer_row**: Insert a claimed review where `claimed_by` references a reviewer_id that has NO row in the reviewers table at all. Run the startup ownership sweep logic. Verify the review is reclaimed to pending.

  21. **test_startup_reclaims_claimed_review_from_foreign_session**: Insert a reviewer row with a DIFFERENT session_token (foreign session). Insert a claimed review with claimed_by referencing that foreign reviewer. Run the startup ownership sweep. Verify the review is reclaimed.

  22. **test_startup_preserves_claimed_review_from_live_current_session_reviewer**: Insert a reviewer row with the CURRENT session_token and status='active'. Insert a claimed review with claimed_by referencing that reviewer. Run the startup ownership sweep. Verify the review is NOT reclaimed -- it remains claimed.

  23. **test_claim_timeout_reclaim_with_null_claimed_at**: Create a review, set its status to 'claimed' and claimed_at to NULL directly in the DB (simulating a legacy row). Set updated_at to a timestamp older than the claim timeout. Run _check_claim_timeouts. Verify the review is reclaimed -- the COALESCE fallback to updated_at (or created_at) makes the NULL claimed_at row reclaimable rather than permanently stuck.

  Use conftest fixtures. For pool-enabled tests, create a helper that constructs AppContext with a ReviewerPool and mocked subprocess. Set up a fixture or factory that provides a SpawnConfig with test-appropriate defaults (short timeouts for fast tests).
  </action>
  <verify>
  Run `cd C:/Projects/gsd-tandem/tools/gsd-review-broker && uv run pytest tests/test_scaling.py -v` -- all 23 tests pass. Run `uv run pytest tests/ -v` -- full suite passes with no regressions.
  </verify>
  <done>
  spawn_reviewer and kill_reviewer MCP tools work with pool cap and ID validation. Reactive scaling triggers on create_review. Background tasks handle idle timeout, TTL expiry, and claim timeout (with COALESCE for NULL claimed_at safety). Startup ownership sweep reclaims ALL orphaned claims (NULL claimed_by, foreign session, missing reviewer row) while preserving live current-session claims. Drain lifecycle completion verified: draining reviewers auto-terminated after terminal verdict or reclaim clears last claim, not terminated when other claims remain. Full test coverage with mocked subprocesses.
  </done>
</task>

</tasks>

<verification>
- `uv run pytest tests/ -v` from tools/gsd-review-broker/ -- ALL tests pass (existing + new)
- spawn_reviewer MCP tool enforces pool cap
- kill_reviewer MCP tool only targets broker-managed IDs
- create_review triggers reactive scaling check
- Background periodic task runs idle/TTL/claim timeout checks
- _check_claim_timeouts uses COALESCE(claimed_at, updated_at, created_at) for NULL safety
- Startup stale session recovery terminates foreign-session reviewers
- Startup ownership sweep reclaims ALL claimed reviews not owned by live current-session reviewers
- Startup preserves claims owned by live current-session reviewers (active/draining)
- Drain lifecycle: draining reviewers auto-terminated when last claim resolved
- Drain lifecycle: NOT terminated when other claims remain
- Pool shutdown terminates all reviewers on broker exit
- Existing broker functionality unchanged when pool=None (no config or no reviewer_pool key)
</verification>

<success_criteria>
Complete reviewer lifecycle management integrated into the broker. Auto-scaling responds to backlog pressure. Background tasks enforce timeouts with NULL-safe claim timeout queries. Startup recovery is comprehensive: terminates stale reviewers AND performs broadened ownership sweep reclaiming all orphaned claims while preserving live current-session claims. Drain lifecycle completion auto-terminates draining reviewers when their last claim is resolved. Manual override tools available. All tests pass including 23 new scaling/integration tests covering drain lifecycle, ownership sweep, and NULL claimed_at fallback. Broker still works normally without pool configuration (backward compatible -- missing reviewer_pool key in config means pool=None).
</success_criteria>

<output>
After completion, create `.planning/phases/07-add-reviewer-lifecycle-management-to-broker/07-04-SUMMARY.md`
</output>
