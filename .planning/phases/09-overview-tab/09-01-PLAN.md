---
phase: 09-overview-tab
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tools/gsd-review-broker/src/gsd_review_broker/dashboard.py
  - tools/gsd-review-broker/tests/test_dashboard.py
autonomous: true
requirements: [OVER-01, OVER-02, OVER-03]

must_haves:
  truths:
    - "GET /dashboard/api/overview returns JSON with broker status, review stats, and reviewer list"
    - "SSE stream pushes overview_update events containing the same data shape as the API response"
    - "Overview data reuses the same queries as get_review_stats and list_reviewers MCP tools"
    - "API endpoint works without reviewer pool configured (reviewer list returns empty)"
  artifacts:
    - path: "tools/gsd-review-broker/src/gsd_review_broker/dashboard.py"
      provides: "JSON API endpoint and SSE data push for overview tab"
      contains: "/dashboard/api/overview"
    - path: "tools/gsd-review-broker/tests/test_dashboard.py"
      provides: "Tests for overview API endpoint and SSE data events"
      contains: "test_overview_api"
  key_links:
    - from: "tools/gsd-review-broker/src/gsd_review_broker/dashboard.py"
      to: "tools/gsd-review-broker/src/gsd_review_broker/tools.py"
      via: "Reuses query logic from get_review_stats and list_reviewers"
      pattern: "get_review_stats|list_reviewers"
    - from: "tools/gsd-review-broker/src/gsd_review_broker/dashboard.py"
      to: "tools/gsd-review-broker/src/gsd_review_broker/db.py"
      via: "Accesses AppContext from server lifespan for database and pool access"
      pattern: "AppContext"
---

<objective>
Create the Python backend for the Overview tab: a JSON REST endpoint for initial page load and SSE data events for live updates.

Purpose: The frontend needs a data source for broker status, aggregate review stats, and active reviewers. The REST endpoint provides initial state; SSE pushes ongoing changes. This must be in place before the Astro frontend can render real data.

Output: Updated dashboard.py with `/dashboard/api/overview` endpoint and SSE overview_update events, plus comprehensive tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-dashboard-shell-and-infrastructure/08-01-SUMMARY.md
@.planning/phases/08-dashboard-shell-and-infrastructure/08-02-SUMMARY.md
@tools/gsd-review-broker/src/gsd_review_broker/dashboard.py
@tools/gsd-review-broker/src/gsd_review_broker/server.py
@tools/gsd-review-broker/src/gsd_review_broker/db.py
@tools/gsd-review-broker/src/gsd_review_broker/tools.py
@tools/gsd-review-broker/tests/test_dashboard.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add overview JSON API endpoint and SSE data push to dashboard.py</name>
  <files>tools/gsd-review-broker/src/gsd_review_broker/dashboard.py</files>
  <action>
Add a JSON REST endpoint and enhance the SSE stream in dashboard.py. The endpoint must be registered BEFORE the catch-all static route (same pattern as /dashboard/events).

**1. Access AppContext from the ASGI app scope:**
The FastMCP lifespan yields an AppContext. To access it from custom route handlers, use the Starlette request's app state. Inspect how FastMCP stores the lifespan context -- it's available via `request.app.state.lifespan_context` or similar. If not directly accessible, store a module-level reference set during SSE connection or use an alternative approach:
- Import `mcp` from `server.py` and access its internal app state
- Or store a reference to the AppContext when the first SSE client connects
- The cleanest approach: add a module-level `_app_context: AppContext | None = None` that gets set by a new `set_app_context(ctx)` function called from the lifespan in db.py

Actually, the simplest proven approach: the `register_dashboard_routes(mcp)` function already receives the mcp instance. Use FastMCP's app state access pattern. Read the mcp instance's internal ASGI app to understand how lifespan context is stored. The context is available at runtime on `request.state` or `request.app.state` -- investigate and use whatever path works.

If no clean path exists through Starlette's request, use a module-level setter pattern:
```python
_app_ctx: AppContext | None = None

def set_app_context(ctx: AppContext) -> None:
    global _app_ctx
    _app_ctx = ctx
```
And call `set_app_context(ctx)` from `broker_lifespan` in db.py right after creating the AppContext.

**2. Create `/dashboard/api/overview` GET endpoint:**
Register this route AFTER /dashboard/events but BEFORE /dashboard and /dashboard/{path:path}.

The endpoint returns a JSON response with this structure:
```json
{
  "broker": {
    "version": "0.1.0",
    "uptime_seconds": 1234.5,
    "address": "0.0.0.0:8321",
    "config": {
      "mode": "yolo",
      "model_profile": "quality",
      "review_granularity": "per_task",
      "execution_mode": "blocking",
      "review_enabled": true,
      "pool_enabled": true,
      "max_pool_size": 3
    }
  },
  "stats": {
    "total_reviews": 42,
    "by_status": {"pending": 1, "claimed": 2, "approved": 30, "changes_requested": 4, "closed": 5},
    "by_category": {"plan_review": 10, "code_review": 32},
    "approval_rate_pct": 88.2,
    "avg_time_to_verdict_seconds": 45.3,
    "avg_review_duration_seconds": 120.7
  },
  "reviewers": {
    "pool_active": true,
    "session_token": "abc123",
    "pool_size": 2,
    "reviewers": [
      {
        "id": "reviewer-1-abc123",
        "display_name": "reviewer-1",
        "status": "active",
        "pid": 12345,
        "spawned_at": "2026-02-26T10:00:00",
        "last_active_at": "2026-02-26T10:05:00",
        "reviews_completed": 5,
        "total_review_seconds": 250.0,
        "approvals": 4,
        "rejections": 1,
        "current_review": "review-id-abc"
      }
    ]
  }
}
```

Implementation details:
- Import `__version__` from `gsd_review_broker`
- Track server start time with a module-level `_start_time = time.monotonic()` set at import
- For broker address: use `"0.0.0.0:8321"` (or read from env like server.py does with BROKER_HOST)
- For config: read from the AppContext's config path. Use `_repo_config_path` pattern from db.py, or read the config.json file directly using the repo_root from AppContext. Extract relevant fields (mode, model_profile, review_granularity, execution_mode, review.enabled, reviewer_pool presence, max_pool_size).
- For stats: execute the same SQL queries as `get_review_stats` in tools.py. Do NOT call the MCP tool function directly (it requires an MCP Context). Instead, extract the query logic into a shared helper or duplicate the essential queries (total, by_status, approval_rate, avg times). Prefer extracting a helper function like `async def _query_review_stats(db: aiosqlite.Connection, project: str | None = None) -> dict` to avoid duplication. This helper could live in dashboard.py or a new shared module. Keep it simple: put it in dashboard.py.
- For reviewers: query the reviewers table directly (same query as list_reviewers). Also query current review assignments: `SELECT id, claimed_by FROM reviews WHERE status = 'claimed'` to map each reviewer to their current review.
- Return `JSONResponse` from starlette.responses.

**3. Enhance SSE stream to push overview data:**
Modify the `event_stream()` async generator in the `/dashboard/events` handler to periodically push overview data alongside heartbeats. Instead of just sending empty heartbeats, alternate with data pushes:

- After the initial "connected" event, immediately push one `overview_update` event with the full overview data
- On each heartbeat interval (every 15 seconds), push an `overview_update` event with fresh data instead of (or in addition to) the heartbeat

The SSE event format:
```
event: overview_update
data: {"type": "overview_update", "broker": {...}, "stats": {...}, "reviewers": {...}}
```

The `event_stream()` generator needs access to AppContext. Since it's a closure inside `register_dashboard_routes`, and the AppContext is available via the module-level `_app_ctx` or via the request, pass it through.

Important: The SSE handler must handle the case where AppContext is not yet available (return empty/default data).

**4. Route registration order in register_dashboard_routes:**
1. `/dashboard/events` (SSE)
2. `/dashboard/api/overview` (JSON API) -- NEW
3. `/dashboard` (index.html)
4. `/dashboard/{path:path}` (static catch-all)

Import JSONResponse from starlette.responses (add to existing import line).
Import time at module level.
Import `__version__` from `gsd_review_broker`.
  </action>
  <verify>
Run `cd C:/Projects/gsd-tandem/tools/gsd-review-broker && uv run python -c "from gsd_review_broker.dashboard import register_dashboard_routes; print('import ok')"` to confirm no import errors.
  </verify>
  <done>
dashboard.py has: (1) module-level app context setter, (2) /dashboard/api/overview returning JSON with broker, stats, reviewers sections, (3) SSE stream pushing overview_update events with full overview data on each heartbeat cycle. Route registration order preserved.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add tests for overview API endpoint and SSE overview data</name>
  <files>tools/gsd-review-broker/tests/test_dashboard.py</files>
  <action>
Add tests to the existing test_dashboard.py file for the new overview API and SSE data features.

**Test fixtures needed:**
- Create a fixture that sets up an in-memory SQLite database with the broker schema, creates an AppContext, and calls `dashboard.set_app_context(ctx)` (or whatever the setter is named). This fixture should also insert some sample review data for stats testing.
- After the test, clear the app context to avoid state leaks.

**Tests to add:**

1. `test_overview_api_returns_json(client)` -- GET /dashboard/api/overview returns 200 with JSON content-type. Verify the response has "broker", "stats", "reviewers" top-level keys.

2. `test_overview_api_broker_section()` -- Verify the broker section contains "version", "uptime_seconds" (>= 0), "address" (string), "config" (dict with expected keys).

3. `test_overview_api_stats_section()` -- Set up AppContext with an in-memory DB, insert a few reviews (some approved, some pending), then call the API. Verify stats.total_reviews matches inserted count, by_status keys present, approval_rate_pct is a number or null.

4. `test_overview_api_reviewers_no_pool()` -- Set up AppContext with pool=None, verify reviewers section has pool_active=false and empty reviewers list.

5. `test_overview_api_reviewers_with_pool()` -- Set up AppContext with a mock pool (mock the pool object and insert reviewer rows in the DB), verify reviewers are returned with expected fields.

6. `test_sse_sends_overview_update()` -- Using the direct handler testing pattern (from existing test_dashboard_sse_endpoint), verify that after the initial "connected" event, an "overview_update" event arrives. Use a very short heartbeat interval (0.05s) for fast testing.

**Testing patterns to follow:**
- Use the existing `app` and `client` fixtures for HTTP tests
- Use the direct route handler pattern for SSE tests (bypass TestClient buffering)
- Use `patch.object(dashboard, ...)` for mocking as established in existing tests
- Use aiosqlite in-memory database for stats tests: `await aiosqlite.connect(":memory:")`
- Import and call `ensure_schema` from db.py to set up tables

**Sample review insertion for stats tests:**
```python
await db.execute("BEGIN IMMEDIATE")
await db.execute(
    "INSERT INTO reviews (id, status, intent, agent_type, agent_role, phase) VALUES (?, ?, ?, ?, ?, ?)",
    ("r1", "approved", "test intent", "executor", "proposer", "01")
)
await db.execute(
    "INSERT INTO reviews (id, status, intent, agent_type, agent_role, phase) VALUES (?, ?, ?, ?, ?, ?)",
    ("r2", "pending", "test intent 2", "planner", "proposer", "02")
)
await db.execute("COMMIT")
```

Run all tests: `cd C:/Projects/gsd-tandem/tools/gsd-review-broker && uv run pytest tests/test_dashboard.py -v`
  </action>
  <verify>
Run `cd C:/Projects/gsd-tandem/tools/gsd-review-broker && uv run pytest tests/test_dashboard.py -v` -- all tests pass (existing + new).
Also run full test suite: `cd C:/Projects/gsd-tandem/tools/gsd-review-broker && uv run pytest -v --tb=short` to verify no regressions.
  </verify>
  <done>
At least 5 new tests pass covering: API endpoint response shape, broker section, stats with real DB data, reviewer list with and without pool, and SSE overview_update event delivery. All existing dashboard tests continue to pass.
  </done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/test_dashboard.py -v` -- all tests pass
2. `uv run python -c "from gsd_review_broker.dashboard import register_dashboard_routes"` -- no import errors
3. All existing tests pass: `uv run pytest -v --tb=short`
</verification>

<success_criteria>
- /dashboard/api/overview returns JSON with broker status (version, uptime, address, config), review stats (total, by_status, approval_rate, avg times), and reviewer list (with per-reviewer stats and current review assignment)
- SSE stream sends overview_update events with the same data shape on each heartbeat cycle
- At least 5 new tests pass covering API response shape, stats accuracy, and SSE data delivery
- No regressions in existing test suite
</success_criteria>

<output>
After completion, create `.planning/phases/09-overview-tab/09-01-SUMMARY.md`
</output>
