---
phase: 09-overview-tab
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tools/gsd-review-broker/src/gsd_review_broker/dashboard.py
  - tools/gsd-review-broker/tests/test_dashboard.py
autonomous: true
requirements: [OVER-01, OVER-02, OVER-03]

must_haves:
  truths:
    - "GET /dashboard/api/overview returns JSON with broker status, review stats, and reviewer list"
    - "SSE stream pushes overview_update data using the default message format (no event: prefix) that sse.ts dispatches by data.type"
    - "Overview data reuses the same queries as get_review_stats and list_reviewers MCP tools"
    - "API endpoint works without reviewer pool configured (reviewer list returns empty)"
  artifacts:
    - path: "tools/gsd-review-broker/src/gsd_review_broker/dashboard.py"
      provides: "JSON API endpoint and SSE data push for overview tab"
      contains: "/dashboard/api/overview"
    - path: "tools/gsd-review-broker/tests/test_dashboard.py"
      provides: "Tests for overview API endpoint and SSE data events"
      contains: "test_overview_api"
  key_links:
    - from: "tools/gsd-review-broker/src/gsd_review_broker/dashboard.py"
      to: "tools/gsd-review-broker/src/gsd_review_broker/tools.py"
      via: "Reuses query logic from get_review_stats and list_reviewers"
      pattern: "get_review_stats|list_reviewers"
    - from: "tools/gsd-review-broker/src/gsd_review_broker/dashboard.py"
      to: "tools/gsd-review-broker/src/gsd_review_broker/db.py"
      via: "Accesses AppContext via module-level _app_ctx setter called from broker_lifespan"
      pattern: "_app_ctx|set_app_context"
---

<objective>
Create the Python backend for the Overview tab: a JSON REST endpoint for initial page load and SSE data events for live updates.

Purpose: The frontend needs a data source for broker status, aggregate review stats, and active reviewers. The REST endpoint provides initial state; SSE pushes ongoing changes. This must be in place before the Astro frontend can render real data.

Output: Updated dashboard.py with `/dashboard/api/overview` endpoint and SSE overview_update data pushes, plus comprehensive tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-dashboard-shell-and-infrastructure/08-01-SUMMARY.md
@.planning/phases/08-dashboard-shell-and-infrastructure/08-02-SUMMARY.md
@tools/gsd-review-broker/src/gsd_review_broker/dashboard.py
@tools/gsd-review-broker/src/gsd_review_broker/server.py
@tools/gsd-review-broker/src/gsd_review_broker/db.py
@tools/gsd-review-broker/src/gsd_review_broker/tools.py
@tools/gsd-review-broker/tests/test_dashboard.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add overview JSON API endpoint and SSE data push to dashboard.py</name>
  <files>tools/gsd-review-broker/src/gsd_review_broker/dashboard.py</files>
  <action>
Add a JSON REST endpoint and enhance the SSE stream in dashboard.py. The endpoint must be registered BEFORE the catch-all static route (same pattern as /dashboard/events).

**1. Access AppContext via module-level setter (ONE approach, no alternatives):**

Add a module-level `_app_ctx` variable and setter function in dashboard.py:
```python
_app_ctx: AppContext | None = None

def set_app_context(ctx: AppContext) -> None:
    global _app_ctx
    _app_ctx = ctx
```

Then in db.py's `broker_lifespan`, right after the `AppContext` is created and before the yield, add:
```python
from gsd_review_broker.dashboard import set_app_context
set_app_context(ctx)
```

This is the ONLY approach. Do NOT attempt `request.app.state.lifespan_context`, `mcp` internals, or any other mechanism. The module-level setter is clean, testable, and avoids circular imports (dashboard imports happen after db.py setup).

**2. Create `/dashboard/api/overview` GET endpoint:**
Register this route AFTER /dashboard/events but BEFORE /dashboard and /dashboard/{path:path}.

The endpoint returns a JSON response with this structure:
```json
{
  "broker": {
    "version": "0.1.0",
    "uptime_seconds": 1234.5,
    "address": "0.0.0.0:8321",
    "config": {
      "mode": "yolo",
      "model_profile": "quality",
      "review_granularity": "per_task",
      "execution_mode": "blocking",
      "review_enabled": true,
      "pool_enabled": true,
      "max_pool_size": 3
    }
  },
  "stats": {
    "total_reviews": 42,
    "by_status": {"pending": 1, "claimed": 2, "approved": 30, "changes_requested": 4, "closed": 5},
    "by_category": {"plan_review": 10, "code_review": 32},
    "approval_rate_pct": 88.2,
    "avg_time_to_verdict_seconds": 45.3,
    "avg_review_duration_seconds": 120.7
  },
  "reviewers": {
    "pool_active": true,
    "session_token": "abc123",
    "pool_size": 2,
    "reviewers": [
      {
        "id": "reviewer-1-abc123",
        "display_name": "reviewer-1",
        "status": "active",
        "pid": 12345,
        "spawned_at": "2026-02-26T10:00:00",
        "last_active_at": "2026-02-26T10:05:00",
        "reviews_completed": 5,
        "total_review_seconds": 250.0,
        "approvals": 4,
        "rejections": 1,
        "current_review": "review-id-abc"
      }
    ]
  }
}
```

Implementation details:
- Import `__version__` from `gsd_review_broker`
- Track server start time with a module-level `_start_time = time.monotonic()` set at import
- For broker address: read from `BROKER_HOST` and `BROKER_PORT` env vars with defaults, matching server.py's pattern: `host = os.environ.get("BROKER_HOST", "0.0.0.0")` and `port = os.environ.get("BROKER_PORT", "8321")`. Format as `f"{host}:{port}"`. Import `os` at module level.
- For config: read from the AppContext's config path. Use `_repo_config_path` pattern from db.py, or read the config.json file directly using the repo_root from AppContext. Extract relevant fields (mode, model_profile, review_granularity, execution_mode, review.enabled, reviewer_pool presence, max_pool_size).
- For stats: execute the same SQL queries as `get_review_stats` in tools.py. Do NOT call the MCP tool function directly (it requires an MCP Context). Instead, extract the query logic into a shared helper or duplicate the essential queries (total, by_status, approval_rate, avg times). Prefer extracting a helper function like `async def _query_review_stats(db: aiosqlite.Connection, project: str | None = None) -> dict` to avoid duplication. This helper could live in dashboard.py or a new shared module. Keep it simple: put it in dashboard.py.
- For reviewers: query the reviewers table directly (same query as list_reviewers). Also query current review assignments: `SELECT id, claimed_by FROM reviews WHERE status = 'claimed'` to map each reviewer to their current review.
- Return `JSONResponse` from starlette.responses.

**3. Enhance SSE stream to push overview data:**
Modify the `event_stream()` async generator in the `/dashboard/events` handler to periodically push overview data alongside heartbeats. Instead of just sending empty heartbeats, alternate with data pushes:

- After the initial "connected" event, immediately push one `overview_update` message with the full overview data
- On each heartbeat interval (every 15 seconds), push an `overview_update` message with fresh data instead of (or in addition to) the heartbeat

**CRITICAL SSE format -- must use default message format (no `event:` prefix):**

The existing SSE client in `sse.ts` uses `eventSource.onmessage` (line 74) which ONLY receives events that have NO `event:` field. It dispatches based on `data.type` (line 35). Therefore:

CORRECT format (received by onmessage, dispatched by data.type):
```
data: {"type": "overview_update", "broker": {...}, "stats": {...}, "reviewers": {...}}

```

WRONG format (NOT received by onmessage -- would need addEventListener):
```
event: overview_update
data: {"type": "overview_update", ...}

```

Do NOT use `event: overview_update` prefix. Send the data as a default/unnamed SSE message with `"type": "overview_update"` inside the JSON payload. This matches how sse.ts dispatches events to subscribers.

Note: The existing `event: connected` and `event: heartbeat` in dashboard.py actually are NOT received by the sse.ts onmessage handler either -- ConnectionStatus uses separate `sse-status` custom events fired from onopen/onerror. So there is no inconsistency; those named events serve a different purpose.

The `event_stream()` generator needs access to AppContext. Since `_app_ctx` is module-level, access it directly inside the generator. Handle the case where `_app_ctx` is None (return empty/default data).

**4. Route registration order in register_dashboard_routes:**
1. `/dashboard/events` (SSE)
2. `/dashboard/api/overview` (JSON API) -- NEW
3. `/dashboard` (index.html)
4. `/dashboard/{path:path}` (static catch-all)

Import JSONResponse from starlette.responses (add to existing import line).
Import time and os at module level.
Import `__version__` from `gsd_review_broker`.
  </action>
  <verify>
Run `cd C:/Projects/gsd-tandem/tools/gsd-review-broker && uv run python -c "from gsd_review_broker.dashboard import register_dashboard_routes; print('import ok')"` to confirm no import errors.
  </verify>
  <done>
dashboard.py has: (1) module-level _app_ctx setter as the single AppContext access pattern, (2) /dashboard/api/overview returning JSON with broker, stats, reviewers sections using BROKER_HOST/BROKER_PORT env vars for address, (3) SSE stream pushing overview_update data using default message format (data: {"type": "overview_update", ...} with NO event: prefix) compatible with sse.ts onmessage dispatch. Route registration order preserved.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add tests for overview API endpoint and SSE overview data</name>
  <files>tools/gsd-review-broker/tests/test_dashboard.py</files>
  <action>
Add tests to the existing test_dashboard.py file for the new overview API and SSE data features.

**Test fixtures needed:**
- Create a fixture that sets up an in-memory SQLite database with the broker schema, creates an AppContext, and calls `dashboard.set_app_context(ctx)` (or whatever the setter is named). This fixture should also insert some sample review data for stats testing.
- After the test, clear the app context to avoid state leaks.

**Tests to add:**

1. `test_overview_api_returns_json(client)` -- GET /dashboard/api/overview returns 200 with JSON content-type. Verify the response has "broker", "stats", "reviewers" top-level keys.

2. `test_overview_api_broker_section()` -- Verify the broker section contains "version", "uptime_seconds" (>= 0), "address" (string), "config" (dict with expected keys).

3. `test_overview_api_stats_section()` -- Set up AppContext with an in-memory DB, insert a few reviews (some approved, some pending), then call the API. Verify stats.total_reviews matches inserted count, by_status keys present, approval_rate_pct is a number or null.

4. `test_overview_api_reviewers_no_pool()` -- Set up AppContext with pool=None, verify reviewers section has pool_active=false and empty reviewers list.

5. `test_overview_api_reviewers_with_pool()` -- Set up AppContext with a mock pool (mock the pool object and insert reviewer rows in the DB), verify reviewers are returned with expected fields.

6. `test_sse_sends_overview_update()` -- Using the direct handler testing pattern (from existing test_dashboard_sse_endpoint), verify that after the initial "connected" event, an "overview_update" message arrives. The message must use the default/unnamed SSE format: `data: {"type": "overview_update", ...}\n\n` with NO `event:` prefix line. Parse the SSE stream output and confirm the JSON payload has `"type": "overview_update"` and contains "broker", "stats", "reviewers" keys. Use a very short heartbeat interval (0.05s) for fast testing.

**Testing patterns to follow:**
- Use the existing `app` and `client` fixtures for HTTP tests
- Use the direct route handler pattern for SSE tests (bypass TestClient buffering)
- Use `patch.object(dashboard, ...)` for mocking as established in existing tests
- Use aiosqlite in-memory database for stats tests: `await aiosqlite.connect(":memory:")`
- Import and call `ensure_schema` from db.py to set up tables

**Sample review insertion for stats tests:**
```python
await db.execute("BEGIN IMMEDIATE")
await db.execute(
    "INSERT INTO reviews (id, status, intent, agent_type, agent_role, phase) VALUES (?, ?, ?, ?, ?, ?)",
    ("r1", "approved", "test intent", "executor", "proposer", "01")
)
await db.execute(
    "INSERT INTO reviews (id, status, intent, agent_type, agent_role, phase) VALUES (?, ?, ?, ?, ?, ?)",
    ("r2", "pending", "test intent 2", "planner", "proposer", "02")
)
await db.execute("COMMIT")
```

Run all tests: `cd C:/Projects/gsd-tandem/tools/gsd-review-broker && uv run pytest tests/test_dashboard.py -v`
  </action>
  <verify>
Run `cd C:/Projects/gsd-tandem/tools/gsd-review-broker && uv run pytest tests/test_dashboard.py -v` -- all tests pass (existing + new).
Also run full test suite: `cd C:/Projects/gsd-tandem/tools/gsd-review-broker && uv run pytest -v --tb=short` to verify no regressions.
  </verify>
  <done>
At least 5 new tests pass covering: API endpoint response shape, broker section, stats with real DB data, reviewer list with and without pool, and SSE overview_update event delivery (verifying default message format with no event: prefix). All existing dashboard tests continue to pass.
  </done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/test_dashboard.py -v` -- all tests pass
2. `uv run python -c "from gsd_review_broker.dashboard import register_dashboard_routes"` -- no import errors
3. All existing tests pass: `uv run pytest -v --tb=short`
</verification>

<success_criteria>
- /dashboard/api/overview returns JSON with broker status (version, uptime, address from BROKER_HOST/BROKER_PORT env vars, config), review stats (total, by_status, approval_rate, avg times), and reviewer list (with per-reviewer stats and current review assignment)
- SSE stream sends overview_update data using default message format (data: {"type": "overview_update", ...} -- no event: prefix) compatible with sse.ts onmessage dispatch
- AppContext accessed via single module-level _app_ctx setter pattern (no alternative approaches)
- At least 5 new tests pass covering API response shape, stats accuracy, and SSE data delivery
- No regressions in existing test suite
</success_criteria>

<output>
After completion, create `.planning/phases/09-overview-tab/09-01-SUMMARY.md`
</output>
